<!-- loio0d71105a29334737b57cc917a1dc8b5b -->

# Metrics

Metrics are quantitative measures used to evaluate the performance of machine generative AI models within SAP AI Core. By tracking and analyzing metrics, you can assess model quality, compare different model versions, and ensure that your prompts generate responses that meet your standards and criteria.

Key features include:

-   **System-Defined Metrics:** SAP AI Core offers a set of predefined evaluation methods and metrics tailored for common LLM tasks, such as text generation, classification, and summarization. System-defined metrics ensure consistency and comparability across different models and experiments.

    For more information, see [System Designed Metrics in SAP AI Core](https://help.sap.com/docs/AI_CORE/360a8f7315e040c193bad1f5c67a3fd1/2ac6a0896b474fe8b6ba614a7b724d58.html).

-   **Custom Metrics:** In addition to system-defined metrics, you can define and register your own custom metrics to address specific evaluation needs. This flexibility allows you to tailor performance measurement to your unique use cases and business requirements.

    For more information, see [Create a Custom Metric](create-a-custom-metric-8519d00.md).

-   **Integration with Evaluations:** Metrics are seamlessly integrated into the evaluation workflows. When you run an evaluation job, you can specify which metrics to compute, and the results are automatically stored and made available for analysis.

    For more information, see [Evaluations](evaluations-14699b0.md).

-   **Analysis:** Metric results can be compared across different model runs, making it easy to identify trends, detect regressions, and select the best-performing models.

    For more information, see [Compare Runs](compare-runs-6dc7cb8.md).


-   **[Create a Custom Metric](create-a-custom-metric-8519d00.md "")**  

-   **[View Metrics](view-metrics-98a63b9.md "")**  


